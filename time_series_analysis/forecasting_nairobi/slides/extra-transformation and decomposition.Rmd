---
title: "Transformation and decomposition"
author: "Bahman Rostami-Tabar"

toc: true
colortheme: monashwhite
output:
  binb::monash:
    fig_width: 7
    fig_height: 3.5
    includes:
      in_header: header.tex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache=TRUE, warning = FALSE)
library(tidyverse)
library(fpp3)
library(ggplot2)
library(lubridate)
library(purrr)
library(transformr) # Just to get it on renv
library(gganimate)
library(latex2exp)
tourism <- tourism |>
  mutate(
    State = recode(State,
      "Australian Capital Territory" = "ACT",
      "New South Wales" = "NSW",
      "Northern Territory" = "NT",
      "Queensland" = "QLD",
      "South Australia" = "SA",
      "Tasmania" = "TAS",
      "Victoria" = "VIC",
      "Western Australia" = "WA"
    )
  )
options(width=50)
elecequip <- as_tsibble(fpp2::elecequip)
```

# Learning outcome
## Learning outcome

You should be able to:

1. Apply required adjustments on time series data before your analysis
2. Understand when time series decomposition would be helpful
3. Decompose time series using STL method

# Per capita adjustments

## Per capita adjustments
\fontsize{13}{14}\sf

```{r gdp-per-capita}
global_economy |>
  filter(Country == "Australia") |>
  autoplot(GDP)
```

## Per capita adjustments
\fontsize{13}{14}\sf

```{r gdp-per-capita2}
global_economy |>
  filter(Country == "Australia") |>
  autoplot(GDP / Population)
```

# Inflation adjustments

## Inflation adjustments
\fontsize{10}{10}\sf

```{r, eval=FALSE}
print_retail <- aus_retail |>
  filter(Industry == "Newspaper and book retailing") |>
  group_by(Industry) |>
  index_by(Year = year(Month)) |>
  summarise(Turnover = sum(Turnover))
aus_economy <- filter(global_economy, Code == "AUS")
print_retail |>
  left_join(aus_economy, by = "Year") |>
  mutate(Adj_turnover = Turnover / CPI) |>
  pivot_longer(c(Turnover, Adj_turnover),
    names_to = "Type", values_to = "Turnover"
  ) |>
  ggplot(aes(x = Year, y = Turnover)) +
  geom_line() +
  facet_grid(vars(Type), scales = "free_y") +
  labs(x = "Years", y = NULL,
       title = "Turnover: Australian print media industry")
```

## Inflation adjustments
\fontsize{10}{10}\sf

```{r, message=FALSE, warning=FALSE, echo=FALSE, fig.height=5, out.height="90%"}
print_retail <- aus_retail |>
  filter(Industry == "Newspaper and book retailing") |>
  group_by(Industry) |>
  index_by(Year = year(Month)) |>
  summarise(Turnover = sum(Turnover))
aus_economy <- filter(global_economy, Code == "AUS")
print_retail |>
  left_join(aus_economy, by = "Year") |>
  mutate(Adj_turnover = Turnover / CPI) |>
  pivot_longer(c(Turnover, Adj_turnover),
    names_to = "Type", values_to = "Turnover"
  ) |>
  ggplot(aes(x = Year, y = Turnover)) +
  geom_line() +
  facet_grid(vars(Type), scales = "free_y") +
  labs(
    x = "Years", y = NULL,
    title = "Turnover: Australian print media industry"
  )
```

# Mathematical transformations

## Variance stabilization

\fontsize{13}{15}\sf

If the data show different variation at different levels of the series, then a transformation can be useful.
\pause

Denote original observations as $y_1,\dots,y_n$ and transformed
observations as $w_1, \dots, w_n$.
\pause

\begin{block}{\footnotesize Mathematical transformations for stabilizing
variation}
\begin{tabular}{llc}
Square root & $w_t = \sqrt{y_t}$ & $\downarrow$ \\[0.2cm]
Cube root & $w_t = \sqrt[3]{y_t}$ & Increasing \\[0.2cm]
Logarithm & $w_t = \text{log}(y_t)$  & strength
\end{tabular}
\end{block}
\pause

Logarithms, in particular, are useful because they are more interpretable: changes in a log value are **relative (percent) changes on the original scale**.

## Variance stabilization
\fontsize{12}{14}\sf

```{r food, echo=TRUE}
food <- aus_retail |>
  filter(Industry == "Food retailing") |>
  summarise(Turnover = sum(Turnover))
```

```{r food-plot, echo = FALSE, fig.height=2.8}
food |> autoplot(Turnover) +
  labs(y = "Turnover ($AUD)")
```

## Variance stabilization
\fontsize{12}{14}\sf

```{r food-sqrt1, echo=TRUE, fig.height=2.8}
food |> autoplot(sqrt(Turnover)) +
  labs(y = "Square root turnover")
```

## Variance stabilization
\fontsize{12}{14}\sf

```{r food-cbrt, echo=TRUE, fig.height=2.8}
food |> autoplot(Turnover^(1 / 3)) +
  labs(y = "Cube root turnover")
```

## Variance stabilization
\fontsize{12}{14}\sf

```{r food-log, echo=TRUE, fig.height=2.8}
food |> autoplot(log(Turnover)) +
  labs(y = "Log turnover")
```

## Variance stabilization
\fontsize{12}{14}\sf

```{r food-inverse, echo=TRUE, fig.height=2.8}
food |> autoplot(-1 / Turnover) +
  labs(y = "Inverse turnover")
```

## Box-Cox transformations

Each of these transformations is close to a member of the
family of \textbf{Box-Cox transformations}:
$$w_t = \left\{\begin{array}{ll}
        \text{log}(y_t),      & \quad \lambda = 0; \\
        (\text{sign}(y_t)|y_t|^\lambda-1)/\lambda ,         & \quad \lambda \ne 0.
\end{array}\right.
$$\pause

* Actually the Bickel-Doksum transformation (allowing for \rlap{$y_t<0$)}
* $\lambda=1$: (No substantive transformation)
* $\lambda=\frac12$: (Square root plus linear transformation)
* $\lambda=0$: (Natural logarithm)
* $\lambda=-1$: (Inverse plus 1)

## Box-Cox transformations

```{r food-anim, cache=TRUE, echo=FALSE, fig.show='animate', interval=1/10, message=FALSE, fig.height=5, fig.width=8, aniopts='controls,buttonsize=0.3cm,width=11.5cm'}
library(rlang)
library(gganimate)
library(latex2exp)
food |>
  mutate(!!!set_names(map(seq(0, 1, 0.01), ~ expr(fabletools::box_cox(Turnover, !!.x))), seq(0, 1, 0.01))) |>
  select(-Turnover) |>
  pivot_longer(-Month, names_to = "lambda", values_to = "Turnover") |>
  mutate(lambda = as.numeric(lambda)) |>
  ggplot(aes(x = Month, y = Turnover)) +
  geom_line() +
  transition_states(1 - lambda, state_length = 0) +
  view_follow() +
  labs(title = "Box-Cox transformed food retailing turnover (lambda = {format(1 - as.numeric(closest_state), digits = 2)})")
```

## Box-Cox transformations

\fontsize{13}{15}\sf

```{r food-lambda, echo=TRUE}
food |>
  features(Turnover, features = guerrero)
```

\pause

* This attempts to balance the seasonal fluctuations and random variation across the series.
* Always check the results.
* A low value of $\lambda$ can give extremely large prediction intervals.

## Box-Cox transformations
\fontsize{13}{14}\sf

```{r food-bc, echo=TRUE,fig.height=2.8}
food |> autoplot(box_cox(Turnover, 0.0524)) +
  labs(y = "Box-Cox transformed turnover")
```

## Transformations
\fontsize{13}{15}\sf

* Often no transformation needed.
* Simple transformations are easier to explain and work well enough.
* Transformations can have very large effect on PI.
* If some data are zero or negative, then use $\lambda>0$.
* `log1p()` can also be useful for data with zeros.
* Choosing logs is a simple way to force forecasts to be positive
* Transformations must be reversed to obtain forecasts on the original scale. (Handled automatically by `fable`.)

# Time series decompositions

## Time series decomposition

Trend-Cycle
: aperiodic changes in level over time.

Seasonal
: (almost) periodic changes in level due to seasonal factors (e.g., the quarter of the year, the month, or day of the week).

\begin{block}{Additive decomposition}\vspace*{-0.3cm}
\[ y_t = S_t + T_t + R_t \]
\end{block}
\begin{tabular}{@{}llp{8cm}@{}}
where & $y_t=$ & data at period $t$ \\
      & $T_t=$ & trend-cycle component at period $t$\\
      & $S_t=$ & seasonal component at period $t$ \\
      & $R_t=$ & remainder component at period $t$
\end{tabular}

## STL decomposition

\fontsize{13}{14}\sf

  *  STL: "Seasonal and Trend decomposition using Loess"
  *  Very versatile and robust.
  *  Seasonal component allowed to change over time, and rate of change controlled by user.
  *  Smoothness of trend-cycle also controlled by user.
  *  Optionally robust to outliers
  *  No trading day or calendar adjustments.
  *  Only additive.
  *  Take logs to get multiplicative decomposition.
  *  Use Box-Cox transformations to get other decompositions.

## US Retail Employment
\fontsize{11}{11}\sf

```{r usretail}
us_retail_employment <- us_employment |>
  filter(year(Month) >= 1990, Title == "Retail Trade") |>
  select(-Series_ID)
us_retail_employment
```

\vspace*{10cm}

## US Retail Employment

```{r dable1}
us_retail_employment |>
  autoplot(Employed) +
  labs(y = "Persons (thousands)", title = "Total employment in US retail")
```

\vspace*{10cm}

## US Retail Employment
\fontsize{11}{11}\sf

```{r dable2}
dcmp <- us_retail_employment |>
  model(stl = STL(Employed))
dcmp
```

\vspace*{10cm}

## US Retail Employment
\fontsize{11}{11}\sf

```{r dable3}
components(dcmp)
```

\vspace*{10cm}

## US Retail Employment

```{r usretail-stl, fig.width=8, fig.height=5}
components(dcmp) |> autoplot()
```

## US Retail Employment

```{r dable4, fig.height=2.7}
us_retail_employment |>
  autoplot(Employed, color = "gray") +
  autolayer(components(dcmp), trend, color = "#D55E00") +
  labs(y = "Persons (thousands)", title = "Total employment in US retail")
```

\vspace*{10cm}

## US Retail Employment

```{r usretail3}
components(dcmp) |> gg_subseries(season_year)
```

## Seasonal adjustment

  *  Useful by-product of decomposition:  an easy way to calculate seasonally adjusted data.
  *  Additive decomposition: seasonally adjusted data given by
$$y_t - S_t = T_t + R_t$$
  *  Multiplicative decomposition: seasonally adjusted data given by
$$y_t / S_t = T_t \times R_t$$

## US Retail Employment

```{r usretail-sa, fig.height=2.7}
us_retail_employment |>
  autoplot(Employed, color = "gray") +
  autolayer(components(dcmp), season_adjust, color = "#0072B2") +
  labs(y = "Persons (thousands)", title = "Total employment in US retail")
```

## Seasonal adjustment

  * We use estimates of $S$ based on past values to seasonally adjust a current value.
  *  Seasonally adjusted series reflect **remainders** as well as **trend**. Therefore they are not "smooth" and "downturns" or "upturns" can be misleading.
  *  It is better to use the trend-cycle component to look for turning points.

## STL decomposition

```{r stlwindowanim, echo=FALSE, warning=FALSE, message=FALSE, fig.show='animate', interval=1/10,  fig.height=5.35, fig.width=8, aniopts='controls,buttonsize=0.3cm,width=11.5cm', eval=TRUE}
s_windows <- seq(5, 55, by = 2)
stl_defs <- purrr::map(s_windows, function(s_window) {
  STL(Employed ~ season(window = s_window), robust = TRUE)
})
names(stl_defs) <- sprintf("season(window=%02d)", s_windows)

us_retail_employment |>
  model(!!!stl_defs) |>
  components() |>
  as_tibble() |>
  pivot_longer(Employed:remainder,
    names_to = "component", names_ptypes = list(component = factor(levels = c("Employed", "trend", "season_year", "remainder"))),
    values_to = "Employed"
  ) |>
  ggplot(aes(x = Month, y = Employed)) +
  geom_line() +
  facet_grid(rows = vars(component), scales = "free_y") +
  labs(
    title = "STL decomposition of US retail employment",
    subtitle = "{closest_state}"
  ) +
  transition_states(.model)
```

\vspace*{10cm}

## STL decomposition

```{r echo = TRUE, results = 'hide'}
us_retail_employment |>
  model(STL(Employed ~ trend(window = 15) + season(window = "periodic"),
    robust = TRUE
  )) |>
  components()
```

\fontsize{12}{13}\sf

  *  `trend(window = ?)` controls wiggliness of trend component.
  *  `season(window = ?)` controls variation on seasonal component.
  *  `season(window = 'periodic')` is equivalent to an infinite window.

## STL decomposition

```{r mstl, fig.width=8.5, fig.height=3.4}
us_retail_employment |>
  model(STL(Employed)) |>
  components() |>
  autoplot()
```

\only<2>{\begin{textblock}{7}(8,0.2)\fontsize{11}{11}\sf
\begin{alertblock}{}
\begin{itemize}\tightlist
\item \texttt{STL()} chooses \texttt{season(window=13)} by default
\item Can include transformations.
\end{itemize}
\end{alertblock}
\end{textblock}}

## STL decomposition
\fontsize{13}{15}\sf

* Algorithm that updates trend and seasonal components iteratively.
* Starts with $\hat{T}_t=0$
* Uses a mixture of loess and moving averages to successively refine the trend and seasonal estimates.
* trend window controls loess bandwidth on deasonalised values.
* season window controls loess bandwidth on detrended subseries.
* Robustness weights based on remainder.
* Default season: `window = 13`
* Default trend:\newline\mbox{}\hfill `window = nextodd(ceiling((1.5*period)/(1-(1.5/s.window)))`
* `window` values should be odd numbers for symmetry.

## Australian holidays

```{r holidays, include=FALSE}
holidays <- tourism |>
  filter(Purpose == "Holiday") |>
  group_by(State) |>
  summarise(Trips = sum(Trips))
```

```{r holidays-plot2, echo=TRUE, dependson="holidays", fig.height=2.8}
holidays |> autoplot(Trips) +
  labs(y = "thousands of trips", x = "Year",
       title = "Australian domestic holiday nights")
```

## Australian holidays

```{r stlagain2, echo=TRUE, warning=FALSE, fig.width=8, fig.height=3}
holidays |>
  model(stl = STL(Trips)) |>
  components() |>
  autoplot()
```

## Holidays decomposition
\fontsize{9}{10}\sf

```{r holidays2}
dcmp <- holidays |>
  model(stl = STL(Trips)) |>
  components()
dcmp
```

## Holidays decomposition
\fontsize{9}{10}\sf

```{r holidays3, fig.height=4.6}
dcmp |> gg_subseries(season_year)
```

## Holidays decomposition
\fontsize{9}{10}\sf

```{r holidays-trend, message=FALSE, warning=FALSE, fig.height=3.5, out.height="70%"}
autoplot(dcmp, trend, scale_bars = FALSE) +
  autolayer(holidays, alpha = 0.4)
```


## Lab Session -transformation

**per capita**

Consider the GDP information in `global_economy`. Plot the GDP per capita for each country over time. Which country has the highest GDP per capita? How has this changed over time?

**transformation**
\fontsize{13}{14}\sf

1. For the following series, find an appropriate transformation in order to stabilise the variance.

    * United States GDP from `global_economy`
    * Slaughter of Victorian “Bulls, bullocks and steers” in `aus_livestock`
    * Victorian Electricity Demand from `vic_elec`.
    * Gas production from `aus_production`

2. Why is a Box-Cox transformation unhelpful for the `canadian_gas` data?

## Lab Session- decomposition
\fontsize{13}{14}\sf

1. Produce the following decomposition

    \fontsize{9}{11}\sf

    ```r
    canadian_gas |>
      model(STL(Volume ~ season(window=7) + trend(window=11))) |>
      components() |>
      autoplot()
    ```

2. What happens as you change the values of the two `window` arguments?

3. How does the seasonal shape change over time? [Hint: Try plotting the seasonal component using `gg_season`.]

4. Can you produce a plausible seasonally adjusted series? [Hint: `season_adjust` is one of the variables returned by `STL`.]
